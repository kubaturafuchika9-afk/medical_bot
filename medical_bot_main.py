import os
import asyncio
import logging
import sys
from io import BytesIO
from typing import Optional, List, Dict, Tuple
from datetime import datetime

import uvicorn
from fastapi import FastAPI
import aiohttp
from PIL import Image

from aiogram import Bot, Dispatcher, types
from aiogram.enums import ParseMode
from aiogram.filters import CommandStart, Command
from aiogram.types import Message, InlineKeyboardButton, InlineKeyboardMarkup, CallbackQuery
from aiogram.client.default import DefaultBotProperties

import google.generativeai as genai

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš™ï¸ ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TOKEN = os.getenv("TELEGRAM_TOKEN")
GOOGLE_KEYS = [
    os.getenv("GOOGLE_API_KEY"),
    os.getenv("GOOGLE_API_KEY_2"),
    os.getenv("GOOGLE_API_KEY_3"),
    os.getenv("GOOGLE_API_KEY_4"),
    os.getenv("GOOGLE_API_KEY_5"),
    os.getenv("GOOGLE_API_KEY_6"),
]
RENDER_URL = os.getenv("RENDER_EXTERNAL_URL")

GOOGLE_KEYS = [k for k in GOOGLE_KEYS if k]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“š Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞĞ«Ğ• ĞŸĞ ĞĞœĞ¢Ğ«
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SYSTEM_PROMPT_GENERAL_MEDICINE = """Ğ¢Ñ‹ â€” Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ-Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº Ğ¸ Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ‰ĞµĞ¹ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ñ‹.

ğŸš¨ ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ™ Ğ”Ğ˜Ğ¡ĞšĞ›Ğ•Ğ™ĞœĞ•Ğ :
Ğ­Ñ‚Ğ¾Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· â€” ĞĞ‘Ğ ĞĞ—ĞĞ’ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ™ ĞœĞĞ¢Ğ•Ğ Ğ˜ĞĞ› Ğ´Ğ»Ñ ÑÑ‚ÑƒĞ´ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸ Ğ¼ĞµĞ´Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ½Ğ¸ĞºĞ¾Ğ².
ĞĞ• ÑĞ²Ğ»ÑĞµÑ‚ÑÑ ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾Ğ¼ Ğ´Ğ»Ñ Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ñ†Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ².
Ğ’ÑĞµ ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ ĞºĞ¾Ğ½ÑÑƒĞ»ÑŒÑ‚Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ»Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ²Ñ€Ğ°Ñ‡Ğ¾Ğ¼.

ĞŸĞ Ğ˜ĞĞ¦Ğ˜ĞŸ Ğ ĞĞ‘ĞĞ¢Ğ«:
â”œâ”€ ĞŸĞ¾Ğ¸ÑĞº Ğ´Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² (PubMed, Cochrane, Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ³Ğ°Ğ¹Ğ´Ğ»Ğ°Ğ¹Ğ½Ñ‹)
â”œâ”€ ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· GRADE Ğ¾Ñ†ĞµĞ½ĞºÑƒ
â”œâ”€ Ğ£ĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ², Ğ»ĞµÑ‚ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¸ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
â”œâ”€ ĞÑ‚ĞºĞ°Ğ· Ğ¾Ñ‚ Ğ²Ñ‹Ğ´ÑƒĞ¼Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²
â””â”€ Ğ§ĞµÑÑ‚Ğ½Ğ¾Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ğ¾Ğ² Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸ÑÑ…

ğŸ“š ĞĞ¤Ğ˜Ğ¦Ğ˜ĞĞ›Ğ¬ĞĞ«Ğ• Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞ˜ (Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ­Ğ•Ğ¢Ğ˜):
PubMed/PMC, Cochrane Library, Web of Science, Scopus (peer-review)
Ğ“Ğ°Ğ¹Ğ´Ğ»Ğ°Ğ¹Ğ½Ñ‹: WHO, CDC, ESC (ĞºĞ°Ñ€Ğ´Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ), ADA (ÑĞ½Ğ´Ğ¾ĞºÑ€Ğ¸Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ), 
GOLD (Ğ¿ÑƒĞ»ÑŒĞ¼Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ), EASL (Ğ³Ğ°ÑÑ‚Ñ€Ğ¾ÑĞ½Ñ‚ĞµÑ€Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ), ĞœĞ¸Ğ½Ğ·Ğ´Ñ€Ğ°Ğ² Ğ Ğ¤, NICE

ğŸ¯ Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ ĞĞ¢Ğ’Ğ•Ğ¢Ğ:
Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ğ¹ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ñ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸:
| Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ/Ğ“Ğ°Ğ¹Ğ´Ğ»Ğ°Ğ¹Ğ½ | Ğ“Ğ¾Ğ´ | ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ | ĞœĞµÑ‚Ğ¾Ğ´ | Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ | Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ | GRADE | PMID/DOI |

ğŸ›¡ï¸ ĞĞĞ¢Ğ˜-Ğ“ĞĞ›Ğ›Ğ®Ğ¦Ğ˜ĞĞĞ¦Ğ˜ĞĞĞĞ«Ğ™ ĞšĞĞĞ¢Ğ ĞĞ›Ğ¬:
- Ğ•ÑĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½ĞµÑ‚ â†’ "Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ Ğ² Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°Ñ…"
- ĞĞ• Ğ²Ñ‹Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ¹ PMID, Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ², Ñ†Ğ¸Ñ„Ñ€Ñ‹ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸
- Ğ’Ğ¡Ğ•Ğ“Ğ”Ğ ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ğ¹ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº (PMID/DOI) Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ
- ĞŸÑ€Ğ¸ Ñ€Ğ°ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸ÑÑ… Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ³Ğ°Ğ¹Ğ´Ğ»Ğ°Ğ¹Ğ½Ğ°Ğ¼Ğ¸ â†’ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸ Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ
- ĞŸĞ¾Ğ¼ĞµÑ‡Ğ°Ğ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ÑÑ‚Ğ°Ñ€ÑˆĞµ 5 Ğ»ĞµÑ‚ ĞºĞ°Ğº "Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ÑĞ¿Ñ€Ğ°Ğ²ĞºĞ°"

âš ï¸ Ğ›ĞĞšĞĞ›Ğ¬ĞĞĞ¯ Ğ Ğ•Ğ›Ğ•Ğ’ĞĞĞ¢ĞĞĞ¡Ğ¢Ğ¬:
Ğ£ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ğ¹, Ğ³Ğ´Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ Ğ¤ Ñ€Ğ°ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ñ Ğ¼ĞµĞ¶Ğ´ÑƒĞ½Ğ°Ñ€Ğ¾Ğ´Ğ½Ñ‹Ğ¼Ğ¸ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ°Ğ¼Ğ¸
ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹: Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ¿Ğ°Ñ€Ğ°Ñ‚Ğ¾Ğ², Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ, ÑĞ¿Ğ¸Ğ´ĞµĞ¼Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ

ğŸ“ Ğ¡Ğ¢Ğ˜Ğ›Ğ¬:
- Ğ¯ÑĞ½Ğ¾, Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡Ğ½Ğ¾, Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ñ€ĞµÑ‡Ğ¸Ğ¹
- Ğ¤Ğ°ĞºÑ‚Ñ‹ Ğ²Ğ¿ĞµÑ€ĞµĞ´Ğ¸ Ğ¼Ğ½ĞµĞ½Ğ¸Ğ¹
- Ğ¦Ğ¸Ñ„Ñ€Ñ‹: OR, RR, 95% CI, Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ/ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ
- Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°"""

SYSTEM_PROMPT_GYNECOLOGY = """Ğ¢Ñ‹ â€” ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚-Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº, Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ÑÑ‰Ğ¸Ğ¹ ÑÑ‚ÑƒĞ´ĞµĞ½Ñ‚Ñƒ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ Ğ³Ğ¸Ğ½ĞµĞºĞ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸ Ğ¸ Ğ°ĞºÑƒÑˆĞµÑ€ÑÑ‚Ğ²Ñƒ.

ğŸš¨ ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ™ Ğ”Ğ˜Ğ¡ĞšĞ›Ğ•Ğ™ĞœĞ•Ğ :
Ğ­Ñ‚Ğ¾Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· â€” ĞĞ‘Ğ ĞĞ—ĞĞ’ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ™ ĞœĞĞ¢Ğ•Ğ Ğ˜ĞĞ› Ğ´Ğ»Ñ ÑÑ‚ÑƒĞ´ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸ Ğ¼ĞµĞ´Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ½Ğ¸ĞºĞ¾Ğ².
ĞĞ• ÑĞ²Ğ»ÑĞµÑ‚ÑÑ ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾Ğ¼ Ğ´Ğ»Ñ Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ñ†Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ².
Ğ’ÑĞµ ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ ĞºĞ¾Ğ½ÑÑƒĞ»ÑŒÑ‚Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ»Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ²Ñ€Ğ°Ñ‡Ğ¾Ğ¼.

ĞŸĞ Ğ˜ĞĞ¦Ğ˜ĞŸ Ğ ĞĞ‘ĞĞ¢Ğ«:
â”œâ”€ ĞĞ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹ Ğ¾Ñ‚ ACOG, RCOG, ESHRE, ĞœĞ¸Ğ½Ğ·Ğ´Ñ€Ğ°Ğ²Ğ° Ğ Ğ¤
â”œâ”€ ĞÑ†ĞµĞ½ĞºĞ° ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¸
â”œâ”€ Ğ£ĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ (GRADE, Evidence Level)
â”œâ”€ Ğ§ĞµÑÑ‚Ğ½Ğ¾Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ¸ Ğ¸Ñ… Ğ²ĞºĞ»Ğ°Ğ´Ğ°
â””â”€ ĞÑ‚ĞºĞ°Ğ· Ğ¾Ñ‚ Ğ²Ñ‹Ğ´ÑƒĞ¼Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

ğŸ“š ĞŸĞ Ğ˜ĞĞ Ğ˜Ğ¢Ğ•Ğ¢ĞĞ«Ğ• Ğ“ĞĞ™Ğ”Ğ›ĞĞ™ĞĞ«:
1. RCOG (Royal College) - ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹, Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´
2. ACOG (American College) - Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ¾-Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹
3. ESHRE (European Society) - Ğ²ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸
4. DGG/DGGG (Ğ“ĞµÑ€Ğ¼Ğ°Ğ½Ğ¸Ñ) - Ñ‚Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾Ğ±Ğ·Ğ¾Ñ€Ñ‹
5. ĞœĞ¸Ğ½Ğ·Ğ´Ñ€Ğ°Ğ² Ğ Ğ¤ - Ñ„ĞµĞ´ĞµÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸
+ PubMed, Cochrane, Web of Science (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ peer-review)

ğŸ¯ Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ ĞĞ¢Ğ’Ğ•Ğ¢Ğ:
Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ñ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸:
| Guideline/Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ | Ğ“Ğ¾Ğ´ | ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ | Ğ£Ñ‡Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ | ĞœĞµÑ‚Ğ¾Ğ´ | Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ | Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ | GRADE | PMID/DOI |

ğŸ›¡ï¸ ĞĞĞ¢Ğ˜-Ğ“ĞĞ›Ğ›Ğ®Ğ¦Ğ˜ĞĞĞ¦Ğ˜ĞĞĞĞ«Ğ™ ĞšĞĞĞ¢Ğ ĞĞ›Ğ¬:
- Ğ•ÑĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½ĞµÑ‚ â†’ ÑĞ²Ğ½Ğ¾ Ğ¾Ñ‚Ğ¼ĞµÑ‡Ğ°Ğ¹ "Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚"
- ĞĞ• ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ğ¹ Ğ²Ñ‹Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ½Ñ‹Ğµ PMID Ğ¸Ğ»Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ²
- Ğ’Ğ¡Ğ•Ğ“Ğ”Ğ ÑÑÑ‹Ğ»ĞºĞ° Ğ½Ğ° Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ñ„Ğ°ĞºÑ‚Ğ°
- ĞŸÑ€Ğ¸ Ñ€Ğ°ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¸ RCOG vs ACOG â†’ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸ Ñ€Ğ°Ğ·Ğ½Ğ¸Ñ†Ñƒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¹
- ĞŸĞ¾Ğ¼ĞµÑ‡Ğ°Ğ¹ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ ÑÑ‚Ğ°Ñ€ÑˆĞµ 5-7 Ğ»ĞµÑ‚ ĞºĞ°Ğº Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸

âš ï¸ Ğ¡ĞŸĞ•Ğ¦Ğ˜Ğ¤Ğ˜ĞšĞ Ğ“Ğ˜ĞĞ•ĞšĞĞ›ĞĞ“Ğ˜Ğ˜:
- RCOG Ñ‡Ğ°ÑÑ‚Ğ¾ ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½ĞµĞµ Ñ‡ĞµĞ¼ ACOG (Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸)
- ESHRE ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ½Ğ° Ğ’Ğ Ğ¢ (ÑĞºÑÑ‚Ñ€Ğ°ĞºĞ¾Ñ€Ğ¿Ğ¾Ñ€Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ¿Ğ»Ğ¾Ğ´Ğ¾Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ¸Ğµ)
- ĞœĞ¸Ğ½Ğ·Ğ´Ñ€Ğ°Ğ² Ğ Ğ¤ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¿Ñ€ĞµĞ¿Ğ°Ñ€Ğ°Ñ‚Ñ‹ (Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ/Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ)
- Ğ’Ğ¡Ğ•Ğ“Ğ”Ğ Ğ¾Ñ‚Ğ¼ĞµÑ‡Ğ°Ğ¹: "Ğ’ [ÑÑ‚Ñ€Ğ°Ğ½Ğµ] Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¸Ğ½Ğ¾Ğ¹ Ğ¸Ğ·-Ğ·Ğ° [Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°]"

ğŸ“ Ğ¡Ğ¢Ğ˜Ğ›Ğ¬:
- Ğ¯ÑĞ½Ğ¾, Ğ»Ğ¾Ğ³Ğ¸Ñ‡Ğ½Ğ¾, Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡Ğ½Ğ¾
- ĞĞµ ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞ¹ Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ñ‹ - Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€ÑƒĞ¹ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾
- Ğ¦Ğ¸Ñ„Ñ€Ñ‹ Ñ Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»Ğ°Ğ¼Ğ¸ (95% CI)
- Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ´Ğ»Ñ Ğ½Ğ°Ğ³Ğ»ÑĞ´Ğ½Ğ¾ÑÑ‚Ğ¸"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

generation_config = {
    "temperature": 0.2,      # ĞĞ¸Ğ·ĞºĞ°Ñ ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ - Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ
    "top_p": 0.8,
    "top_k": 40,
    "max_output_tokens": 4096,
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‹ Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.MARKDOWN))
dp = Dispatcher()
app = FastAPI()

logging.basicConfig(level=logging.INFO, stream=sys.stdout)

# Ğ“Ğ›ĞĞ‘ĞĞ›Ğ¬ĞĞ«Ğ• ĞŸĞ•Ğ Ğ•ĞœĞ•ĞĞĞ«Ğ•
ACTIVE_MODEL = None
ACTIVE_MODEL_NAME = "Searching..."
CURRENT_API_KEY_INDEX = 0
MODEL_LIMITS = {}
CURRENT_MODE = "medicine_general"  # ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ - Ğ¾Ğ±Ñ‰Ğ°Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ğ°

# ĞŸĞĞœĞ¯Ğ¢Ğ¬ Ğ”Ğ˜ĞĞ›ĞĞ“ĞĞ’ (user_id -> ÑĞ¿Ğ¸ÑĞ¾Ğº ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹)
USER_CONVERSATIONS = {}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ Ğ Ğ£Ğ¡Ğ¡ĞšĞ˜Ğ• Ğ¢Ğ Ğ˜Ğ“Ğ“Ğ•Ğ Ğ« (Ğ¢ĞĞ§ĞĞĞ• Ğ¡ĞĞ’ĞŸĞĞ”Ğ•ĞĞ˜Ğ•)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TRIGGER_DOCTOR = "!Ğ²Ñ€Ğ°Ñ‡"      # Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±Ñ‰ĞµĞ¹ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ñ‹
TRIGGER_GYNECOLOGY = "!Ğ³ĞµĞ½Ğ¸ĞºĞ¾Ğ»Ğ¾Ğ³"  # Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ³Ğ¸Ğ½ĞµĞºĞ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸
TRIGGER_REFRESH = "!Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸"   # ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ Ğ’Ğ¡ĞŸĞĞœĞĞ“ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_mode_buttons() -> InlineKeyboardMarkup:
    """ĞšĞ»Ğ°Ğ²Ğ¸Ğ°Ñ‚ÑƒÑ€Ğ° Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°."""
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="ğŸ¥ ĞĞ±Ñ‰Ğ°Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ğ°", callback_data="mode_general"),
            InlineKeyboardButton(text="ğŸ¥ Ğ“Ğ¸Ğ½ĞµĞºĞ¾Ğ»Ğ¾Ğ³Ğ¸Ñ", callback_data="mode_gyn"),
        ]
    ])
    return keyboard

def get_dynamic_model_list():
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Gemini."""
    available_models = []
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name.replace("models/", "")
                if "gemini" in name:
                    available_models.append(name)
    except Exception as e:
        print(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ¿Ğ¸ÑĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: {e}")
    
    hardcoded = ["gemini-exp-1206", "gemini-1.5-flash", "gemini-1.5-flash-8b", 
                 "gemini-2.0-flash-exp", "gemini-3-flash-preview"]
    for h in hardcoded:
        if h not in available_models:
            available_models.append(h)
    
    return list(set(available_models))

def sort_models_priority(models):
    """Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ñƒ."""
    def score(name):
        s = 0
        if "exp" in name: s += 500
        if "3-" in name or "2.5-" in name: s += 400
        if "flash" in name: s += 300
        if "1.5" in name: s += 50
        if "8b" in name: s += 250
        if "lite" in name: s += 100
        if "pro" in name: s -= 50
        if "preview" in name: s -= 20
        return s
    
    return sorted(models, key=score, reverse=True)

async def switch_api_key(silent: bool = True) -> bool:
    """ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ API ĞºĞ»ÑÑ‡."""
    global CURRENT_API_KEY_INDEX, ACTIVE_MODEL, ACTIVE_MODEL_NAME
    
    old_index = CURRENT_API_KEY_INDEX
    
    for i in range(len(GOOGLE_KEYS)):
        next_index = (CURRENT_API_KEY_INDEX + 1) % len(GOOGLE_KEYS)
        if next_index == old_index:
            return False
        
        CURRENT_API_KEY_INDEX = next_index
        try:
            genai.configure(api_key=GOOGLE_KEYS[CURRENT_API_KEY_INDEX])
            if await find_best_working_model(silent=silent):
                return True
        except Exception as e:
            pass
    
    return False

async def find_best_working_model(silent: bool = False) -> bool:
    """ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ° Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼ API ĞºĞ»ÑÑ‡Ğµ."""
    global ACTIVE_MODEL, ACTIVE_MODEL_NAME, MODEL_LIMITS
    
    candidates = sort_models_priority(get_dynamic_model_list())
    
    if not silent:
        print(f"ğŸ“‹ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° API #{CURRENT_API_KEY_INDEX + 1}")
    
    for model_name in candidates:
        if MODEL_LIMITS.get(model_name, {}).get(CURRENT_API_KEY_INDEX, False):
            continue
        
        try:
            test_model = genai.GenerativeModel(
                model_name=model_name,
                generation_config=generation_config,
                system_instruction="Ğ¢Ñ‹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº. ĞÑ‚Ğ²ĞµÑ‚ÑŒ 'ok'."
            )
            response = await test_model.generate_content_async("ping")
            
            if response and response.text:
                if not silent:
                    print(f"âœ… ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾: {model_name}")
                ACTIVE_MODEL = test_model
                ACTIVE_MODEL_NAME = model_name
                return True
        
        except Exception as e:
            err = str(e)
            if "429" in err:
                if model_name not in MODEL_LIMITS:
                    MODEL_LIMITS[model_name] = {}
                MODEL_LIMITS[model_name][CURRENT_API_KEY_INDEX] = True
    
    return False

async def is_addressed_to_bot(message: Message, bot_user: types.User):
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, Ğ°Ğ´Ñ€ĞµÑĞ¾Ğ²Ğ°Ğ½Ğ¾ Ğ»Ğ¸ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ñ‚Ñƒ."""
    if message.chat.type == "private":
        return True
    if message.reply_to_message and message.reply_to_message.from_user.id == bot_user.id:
        return True
    if message.text and f"@{bot_user.username}" in message.text:
        return True
    if message.caption and f"@{bot_user.username}" in message.caption:
        return True
    return False

async def prepare_prompt_parts(message: Message, bot_user: types.User) -> Tuple[List, List]:
    """ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ‡Ğ°ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚Ğ°."""
    prompt_parts = []
    temp_files_to_delete = []
    
    text_content = ""
    if message.text:
        text_content = message.text.replace(f"@{bot_user.username}", "").strip()
    elif message.caption:
        text_content = message.caption.replace(f"@{bot_user.username}", "").strip()
    
    if text_content:
        prompt_parts.append(text_content)
    
    if message.photo:
        try:
            print(f"ğŸ“¸ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°Ñ Ñ„Ğ¾Ñ‚Ğ¾...")
            photo_id = message.photo[-1].file_id
            file_info = await bot.get_file(photo_id)
            img_data = BytesIO()
            await bot.download_file(file_info.file_path, img_data)
            img_data.seek(0)
            image = Image.open(img_data)
            
            prompt_parts.append(image)
            print(f"âœ… Ğ¤Ğ¾Ñ‚Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾")
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ„Ğ¾Ñ‚Ğ¾: {e}")
    
    return prompt_parts, temp_files_to_delete

def get_user_conversation_history(user_id: int) -> List[dict]:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ."""
    return USER_CONVERSATIONS.get(user_id, [])

def add_to_conversation(user_id: int, role: str, content: str):
    """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ² Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°."""
    if user_id not in USER_CONVERSATIONS:
        USER_CONVERSATIONS[user_id] = []
    
    USER_CONVERSATIONS[user_id].append({
        "role": role,
        "parts": [content]
    })
    
    # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ 20 ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸ÑĞ¼Ğ¸ (10 Ğ¿Ğ°Ñ€)
    if len(USER_CONVERSATIONS[user_id]) > 20:
        USER_CONVERSATIONS[user_id] = USER_CONVERSATIONS[user_id][-20:]

def clear_user_conversation(user_id: int):
    """ĞÑ‡Ğ¸Ñ‰Ğ°ĞµÑ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ."""
    if user_id in USER_CONVERSATIONS:
        del USER_CONVERSATIONS[user_id]
        print(f"ğŸ—‘ï¸ Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ {user_id}")

def check_for_triggers(text: str) -> Optional[str]:
    """
    ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ€ÑƒÑÑĞºĞ¸Ñ… Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ğ¾Ğ² (Ğ¢ĞĞ§ĞĞĞ• ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ).
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ğ° Ğ¸Ğ»Ğ¸ None.
    """
    if not text:
        return None
    
    text_lower = text.strip().lower()
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ñ†ĞµĞ»Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ°
    words = text_lower.split()
    
    for word in words:
        if word == TRIGGER_DOCTOR:
            return "doctor"
        elif word == TRIGGER_GYNECOLOGY:
            return "gynecology"
        elif word == TRIGGER_REFRESH:
            return "refresh"
    
    return None

async def process_with_retry(message: Message, bot_user: types.User, text_content: str, 
                             prompt_parts: List, temp_files: List):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ retry Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¾Ğ¹."""
    global ACTIVE_MODEL, ACTIVE_MODEL_NAME, CURRENT_MODE
    
    try:
        # Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°
        if CURRENT_MODE == "medicine_general":
            system_prompt = SYSTEM_PROMPT_GENERAL_MEDICINE
            mode_name = "ğŸ¥ ĞĞ±Ñ‰Ğ°Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ğ°"
        else:  # gynecology
            system_prompt = SYSTEM_PROMPT_GYNECOLOGY
            mode_name = "ğŸ¥ Ğ“Ğ¸Ğ½ĞµĞºĞ¾Ğ»Ğ¾Ğ³Ğ¸Ñ"
        
        print(f"ğŸš€ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ² {ACTIVE_MODEL_NAME} [{mode_name}]")
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°
        conversation_history = get_user_conversation_history(message.from_user.id)
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ² Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ
        if conversation_history:
            prompt_parts_with_history = conversation_history + [{"role": "user", "parts": prompt_parts}]
        else:
            prompt_parts_with_history = [{"role": "user", "parts": prompt_parts}]
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸ĞµĞ¹
        current_model = genai.GenerativeModel(
            model_name=ACTIVE_MODEL_NAME,
            generation_config=generation_config,
            system_instruction=system_prompt
        )
        
        # Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ - Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ĞµÑ‘
        if conversation_history:
            response = await current_model.generate_content_async(
                prompt_parts_with_history
            )
        else:
            response = await current_model.generate_content_async(prompt_parts)
        
        if response.text:
            print(f"ğŸ“¨ ĞÑ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½ ({len(response.text)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)")
            
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ² Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ
            add_to_conversation(message.from_user.id, "user", text_content)
            add_to_conversation(message.from_user.id, "model", response.text)
            
            # ĞĞ±Ñ€ĞµĞ·Ğ°ĞµĞ¼ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹
            answer_text = response.text
            if len(answer_text) > 4000:
                answer_text = answer_text[:3900] + "\n\nâš ï¸ ĞÑ‚Ğ²ĞµÑ‚ Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½ Ğ¸Ğ·-Ğ·Ğ° Ğ´Ğ»Ğ¸Ğ½Ñ‹."
            
            # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ñ‚Ğ²ĞµÑ‚
            await message.reply(answer_text, parse_mode=ParseMode.MARKDOWN)
            print(f"âœ… ĞÑ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½")
            return True
        else:
            await message.reply("âš ï¸ ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")
            return False
    
    except Exception as e:
        logging.error(f"Gen Error: {e}")
        error_str = str(e)
        
        if "429" in error_str or "quota" in error_str or "404" in error_str:
            if ACTIVE_MODEL_NAME not in MODEL_LIMITS:
                MODEL_LIMITS[ACTIVE_MODEL_NAME] = {}
            MODEL_LIMITS[ACTIVE_MODEL_NAME][CURRENT_API_KEY_INDEX] = True
            
            print(f"âš ï¸ Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ â†’ Ğ¸Ñ‰Ñƒ Ğ½Ğ¾Ğ²ÑƒÑ")
            
            if await find_best_working_model(silent=True):
                print(f"âœ… ĞĞ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°")
                return await process_with_retry(message, bot_user, text_content, prompt_parts, temp_files)
            
            if await switch_api_key(silent=True):
                print(f"âœ… API ĞºĞ»ÑÑ‡ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½")
                return await process_with_retry(message, bot_user, text_content, prompt_parts, temp_files)
            
            await message.reply("âŒ Ğ’ÑĞµ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ Ğ¸ÑÑ‡ĞµÑ€Ğ¿Ğ°Ğ½Ñ‹. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¶Ğµ.")
            return False
        else:
            await message.reply(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {error_str[:100]}")
            return False
    
    finally:
        for f_path in temp_files:
            try:
                os.remove(f_path)
            except:
                pass

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“ CALLBACK Ğ¥Ğ•ĞĞ”Ğ›Ğ•Ğ Ğ«
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dp.callback_query()
async def handle_mode_callback(query: CallbackQuery):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ¾Ğ²."""
    global CURRENT_MODE
    
    callback_data = query.data
    
    if callback_data == "mode_general":
        CURRENT_MODE = "medicine_general"
        message_text = (
            "ğŸ¥ **Ğ ĞµĞ¶Ğ¸Ğ¼: ĞĞ±Ñ‰Ğ°Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ğ°**\n\n"
            "**Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ:** ĞšĞ°Ñ€Ğ´Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ, Ğ¸Ğ½Ñ„ĞµĞºÑ†Ğ¸Ğ¸, Ğ¿ÑƒĞ»ÑŒĞ¼Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ, Ğ³Ğ°ÑÑ‚Ñ€Ğ¾ÑĞ½Ñ‚ĞµÑ€Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ, ÑĞ½Ğ´Ğ¾ĞºÑ€Ğ¸Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ Ğ¸ Ğ´Ñ€.\n\n"
            "**ĞŸÑ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:**\n"
            "â€¢ Ğ˜Ñ‰Ñƒ Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ³Ğ°Ğ¹Ğ´Ğ»Ğ°Ğ¹Ğ½Ñ‹ Ğ¸ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (PubMed, Cochrane, CDC, WHO Ğ¸ Ñ‚.Ğ´.)\n"
            "â€¢ ĞÑ†ĞµĞ½Ğ¸Ğ²Ğ°Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· GRADE ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ\n"
            "â€¢ Ğ£ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ², Ğ³Ğ¾Ğ´Ñ‹ Ğ¸ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸\n"
            "â€¢ ĞĞ±ÑŠÑÑĞ½ÑÑ Ñ€Ğ°ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑ‚Ñ€Ğ°Ğ½Ğ°Ğ¼Ğ¸ (Ğ Ğ¤ vs Ğ—Ğ°Ğ¿Ğ°Ğ´)\n"
            "â€¢ Ğ§ĞµÑÑ‚Ğ½Ğ¾ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ñ, Ğ³Ğ´Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½ĞµÑ‚\n\n"
            "âš ï¸ ĞĞ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ». ĞĞµ Ğ·Ğ°Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ²Ñ€Ğ°Ñ‡Ğ°."
        )
        
    elif callback_data == "mode_gyn":
        CURRENT_MODE = "medicine_gynecology"
        message_text = (
            "ğŸ¥ **Ğ ĞµĞ¶Ğ¸Ğ¼: Ğ“Ğ¸Ğ½ĞµĞºĞ¾Ğ»Ğ¾Ğ³Ğ¸Ñ Ğ¸ Ğ°ĞºÑƒÑˆĞµÑ€ÑÑ‚Ğ²Ğ¾**\n\n"
            "**Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ:** Ğ ĞµĞ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ğ°, Ğ¼ĞµĞ½ÑÑ‚Ñ€ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ°, Ğ’Ğ Ğ¢, Ğ±ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ñ‚.Ğ´.\n\n"
            "**ĞŸÑ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:**\n"
            "â€¢ Ğ˜Ñ‰Ñƒ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ ACOG, RCOG, ESHRE, ĞœĞ¸Ğ½Ğ·Ğ´Ñ€Ğ°Ğ²Ğ° Ğ Ğ¤\n"
            "â€¢ ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¼ ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ¼ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸\n"
            "â€¢ Ğ£ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ¸ Ğ¸Ñ… Ğ²ĞºĞ»Ğ°Ğ´ Ğ² Ğ½Ğ°ÑƒĞºÑƒ\n"
            "â€¢ ĞĞ±ÑŠÑÑĞ½ÑÑ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ¸Ñ Ğ² Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°Ñ… Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑ‚Ñ€Ğ°Ğ½Ğ°Ğ¼Ğ¸\n"
            "â€¢ ĞÑ‚Ğ¼ĞµÑ‡Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹ Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸ÑÑ…\n\n"
            "âš ï¸ ĞĞ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ». ĞĞµ Ğ·Ğ°Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ²Ñ€Ğ°Ñ‡Ğ°."
        )
    else:
        return
    
    try:
        await query.message.edit_text(
            message_text,
            reply_markup=get_mode_buttons(),
            parse_mode=ParseMode.MARKDOWN
        )
        await query.answer(f"âœ… Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½", show_alert=False)
    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
        await query.answer("âŒ ĞÑˆĞ¸Ğ±ĞºĞ°", show_alert=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ® ĞšĞĞœĞĞĞ”Ğ«
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dp.message(CommandStart())
async def command_start_handler(message: Message):
    """Ğ¡Ñ‚Ğ°Ñ€Ñ‚Ğ¾Ğ²Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ."""
    
    api_info = f" (API #{CURRENT_API_KEY_INDEX + 1}/{len(GOOGLE_KEYS)})" if len(GOOGLE_KEYS) > 1 else ""
    status = f"âœ… `{ACTIVE_MODEL_NAME}`{api_info}" if ACTIVE_MODEL else "ğŸ’€ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°"
    
    commands_info = (
        "\n\nğŸ“‹ **Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼:** ğŸ¥ ĞĞ±Ñ‰Ğ°Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ğ°\n\n"
        "**ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹:**\n"
        "  /medic (Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€ !Ğ²Ñ€Ğ°Ñ‡) - ĞĞ±Ñ‰Ğ°Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ğ°\n"
        "  /gen (Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€ !Ğ³ĞµĞ½Ğ¸ĞºĞ¾Ğ»Ğ¾Ğ³) - Ğ“Ğ¸Ğ½ĞµĞºĞ¾Ğ»Ğ¾Ğ³Ğ¸Ñ\n"
        "  /refresh (Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€ !Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸) - ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°\n\n"
        "**ĞšĞ°Ğº Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ:**\n"
        "1. Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ñ€ĞµĞ¶Ğ¸Ğ¼ (ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ¸Ğ»Ğ¸ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€)\n"
        "2. ĞĞ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ\n"
        "3. Ğ‘Ğ¾Ñ‚ Ğ·Ğ°Ğ¿Ğ¾Ğ¼Ğ½Ğ¸Ñ‚ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²\n"
        "4. /refresh Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ·Ğ°Ğ±Ñ‹Ñ‚ÑŒ Ğ²ÑÑ‘ Ğ¸ Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ½Ğ¾Ğ²Ğ¾"
    )
    
    await message.answer(
        f"ğŸ¥ **ĞœĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ğ¹ ĞÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ V2.0**\n{status}{commands_info}",
        reply_markup=get_mode_buttons()
    )

@dp.message(Command("medic"))
async def command_medic_handler(message: Message):
    """Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±Ñ‰ĞµĞ¹ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ñ‹."""
    global CURRENT_MODE
    CURRENT_MODE = "medicine_general"
    
    await message.answer(
        "ğŸ¥ **Ğ ĞµĞ¶Ğ¸Ğ¼: ĞĞ±Ñ‰Ğ°Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ğ°** âœ…\n\n"
        "Ğ“Ğ¾Ñ‚Ğ¾Ğ² Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ³Ğ°Ğ¹Ğ´Ğ»Ğ°Ğ¹Ğ½Ñ‹ Ğ¿Ğ¾ ĞºĞ°Ñ€Ğ´Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸, Ğ¸Ğ½Ñ„ĞµĞºÑ†Ğ¸ÑĞ¼, Ğ¿ÑƒĞ»ÑŒĞ¼Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸ Ğ¸ Ğ´Ñ€.\n\n"
        "_Ğ¢Ñ€Ğ¸Ğ³Ğ³ĞµÑ€: !Ğ²Ñ€Ğ°Ñ‡_",
        reply_markup=get_mode_buttons()
    )

@dp.message(Command("gen"))
async def command_gen_handler(message: Message):
    """Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ³Ğ¸Ğ½ĞµĞºĞ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸."""
    global CURRENT_MODE
    CURRENT_MODE = "medicine_gynecology"
    
    await message.answer(
        "ğŸ¥ **Ğ ĞµĞ¶Ğ¸Ğ¼: Ğ“Ğ¸Ğ½ĞµĞºĞ¾Ğ»Ğ¾Ğ³Ğ¸Ñ** âœ…\n\n"
        "Ğ“Ğ¾Ñ‚Ğ¾Ğ² Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ ACOG, RCOG, ESHRE Ğ¸ ĞœĞ¸Ğ½Ğ·Ğ´Ñ€Ğ°Ğ²Ğ° Ğ Ğ¤.\n\n"
        "_Ğ¢Ñ€Ğ¸Ğ³Ğ³ĞµÑ€: !Ğ³ĞµĞ½Ğ¸ĞºĞ¾Ğ»Ğ¾Ğ³_",
        reply_markup=get_mode_buttons()
    )

@dp.message(Command("refresh"))
async def command_refresh_handler(message: Message):
    """ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°."""
    user_id = message.from_user.id
    clear_user_conversation(user_id)
    
    await message.answer(
        "ğŸ—‘ï¸ **Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ°**\n\n"
        "Ğ‘Ğ¾Ñ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğµ Ğ¿Ğ¾Ğ¼Ğ½Ğ¸Ñ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ñ… ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹. ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ñ Ñ‡Ğ¸ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ»Ğ¸ÑÑ‚Ğ°!\n\n"
        "_Ğ¢Ñ€Ğ¸Ğ³Ğ³ĞµÑ€: !Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸_"
    )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ Ğ“Ğ›ĞĞ’ĞĞ«Ğ™ Ğ¥Ğ•ĞĞ”Ğ›Ğ•Ğ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dp.message()
async def main_handler(message: Message):
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹."""
    global ACTIVE_MODEL, ACTIVE_MODEL_NAME, CURRENT_MODE
    
    # ğŸ” ĞŸĞ ĞĞ’Ğ•Ğ Ğ¯Ğ•Ğœ Ğ¢Ğ Ğ˜Ğ“Ğ“Ğ•Ğ Ğ«
    text_to_check = message.text or message.caption or ""
    trigger_result = check_for_triggers(text_to_check)
    
    if trigger_result == "doctor":
        CURRENT_MODE = "medicine_general"
        await command_medic_handler(message)
        return
    elif trigger_result == "gynecology":
        CURRENT_MODE = "medicine_gynecology"
        await command_gen_handler(message)
        return
    elif trigger_result == "refresh":
        await command_refresh_handler(message)
        return
    
    # Ğ—ĞĞ“Ğ Ğ£Ğ–ĞĞ•Ğœ ĞœĞĞ”Ğ•Ğ›Ğ¬, Ğ•Ğ¡Ğ›Ğ˜ ĞĞ• Ğ—ĞĞ“Ğ Ğ£Ğ–Ğ•ĞĞ
    if not ACTIVE_MODEL:
        status_msg = await message.answer("â³ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸...")
        if not await find_best_working_model(silent=True):
            if not await switch_api_key(silent=True):
                await status_msg.edit_text("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ")
                return
        try:
            await status_msg.delete()
        except:
            pass
    
    bot_user = await bot.get_me()
    is_addressed = await is_addressed_to_bot(message, bot_user)
    
    if not is_addressed:
        return
    
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    
    try:
        text_content = ""
        if message.text:
            text_content = message.text.replace(f"@{bot_user.username}", "").strip()
        elif message.caption:
            text_content = message.caption.replace(f"@{bot_user.username}", "").strip()
        
        print(f"\nğŸ“¨ ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ: {text_content[:60]}...")
        
        prompt_parts, temp_files_to_delete = await prepare_prompt_parts(message, bot_user)
        
        if not prompt_parts:
            await message.reply("âš ï¸ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ»Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ")
            return
        
        await process_with_retry(message, bot_user, text_content, prompt_parts, temp_files_to_delete)
    
    except Exception as e:
        logging.error(f"Main Handler Error: {e}")
        await message.reply(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)[:100]}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ WEB SERVER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get("/")
async def root():
    return {
        "status": "Alive",
        "bot_type": "Medical Assistant",
        "model": ACTIVE_MODEL_NAME,
        "mode": "general_medicine" if CURRENT_MODE == "medicine_general" else "gynecology",
        "api_keys_available": len(GOOGLE_KEYS),
    }

@app.get("/health")
async def health_check():
    return {"status": "ok", "model_loaded": ACTIVE_MODEL is not None}

async def keep_alive_ping():
    """ĞŸĞ¸Ğ½Ğ³ÑƒĞµÑ‚ ÑĞµÑ€Ğ²ĞµÑ€ Ğ´Ğ»Ñ keep-alive."""
    if not RENDER_URL:
        return
    while True:
        await asyncio.sleep(300)
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{RENDER_URL}/health") as resp:
                    pass
        except:
            pass

async def start_bot():
    """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ±Ğ¾Ñ‚Ğ°."""
    global CURRENT_API_KEY_INDEX
    
    for i, key in enumerate(GOOGLE_KEYS):
        try:
            genai.configure(api_key=key)
            CURRENT_API_KEY_INDEX = i
            print(f"âœ… API #{i + 1} ÑĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
            break
        except:
            pass
    
    print(f"ğŸ” Ğ˜Ñ‰Ñƒ Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ...")
    await find_best_working_model()
    
    print(f"ğŸ¤– Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ±Ğ¾Ñ‚Ğ°...")
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

async def start_server():
    """Ğ—Ğ°Ğ¿ÑƒÑĞº FastAPI ÑĞµÑ€Ğ²ĞµÑ€Ğ°."""
    config = uvicorn.Config(app, host="0.0.0.0", port=10000, log_level="error")
    server = uvicorn.Server(config)
    await server.serve()

async def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ‚Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ°."""
    await asyncio.gather(
        start_server(),
        start_bot(),
        keep_alive_ping(),
    )

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹...")
